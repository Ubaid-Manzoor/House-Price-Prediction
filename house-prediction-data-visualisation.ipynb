{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data_path = \"../input/train.csv\"\ntest_data_path = \"../input/test.csv\"\nsample_data_path = \"../input/sample_submission.csv\"\n\nX = pd.read_csv(train_data_path)\nfinal_test_data = pd.read_csv(test_data_path)\nID = final_test_data.Id\nsec_X = X.copy()\n#Drop the Rows With SalePrice Missing\nX.dropna(axis=0 , subset=['SalePrice'] , inplace=True)\ny = X.SalePrice\nX.drop(['SalePrice'] , axis=1 , inplace=True)\n\nX.drop(['Id'] , axis=1 ,inplace=True)\nfinal_test_data.drop(['Id'] , axis=1 , inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4129d38a98838be2a25029619177eab32b8c3e53"},"cell_type":"code","source":"X.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c727c8cb19bec9b199907deacf10e1faa574509b"},"cell_type":"code","source":"X.dtypes[30:80]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96bf8de825ca90e52b040a20bf196d24d003f64a"},"cell_type":"code","source":"numerical_columns = X.select_dtypes(include=['int64' , 'float64']).columns.tolist()\ncatagorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n# ordinal_columns = \n#numerical_columns = numerical_columns+ordinal_columns\n# _cat_cols = ['YrSold' , 'MoSold','GarageYrBlt' ,'BsmtFullBath' , 'BsmtHalfBath']\n# catagorical_columns.extend(_cat_cols)\n# for element in [ 'YrSold' , 'MoSold','BsmtFullBath' , 'BsmtHalfBath' ,'GarageCars']:\n#     numerical_columns.remove(element)\n# X[_cat_cols+ordinal_columns] = X[_cat_cols+ordinal_columns].astype(str)\n# final_test_data[_cat_cols+ordinal_columns] = final_test_data[_cat_cols+ordinal_columns].astype(str)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afadf8692b24c4fa0dd3907372bf5270c108f414"},"cell_type":"code","source":"math_data = X[numerical_columns].describe()\nmath_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc50eb346a13789a253178b71a045e06f87d3bb3"},"cell_type":"code","source":"value_100per = math_data.loc[['max']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23ffcf13e24fa5f206b2b6651f10e48ed12d1c16"},"cell_type":"markdown","source":"<h1>Visualization</h1> "},{"metadata":{"trusted":true,"_uuid":"e77808bc1244c42cdc819dea8b8cd861ddadf59e"},"cell_type":"code","source":"# import matplotlib as mpl\n# import matplotlib.pyplot as plt\n# import seaborn as sb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87ba3aff9e49f032e626739ced4d23eef817c619"},"cell_type":"code","source":"\n# for cols in (catagorical_columns):\n#     if X[cols].dtype in [\"int64\" , \"float64\"]:\n#         if len(X[cols].value_counts()) > 15:\n#             sb.kdeplot(X[cols].sort_index())\n#         else:\n#             (X[cols].value_counts().sort_index() / len(X)).plot.bar()\n#     else:\n#         (X[cols].value_counts() / len(X)).plot.bar()\n#     plt.ylabel('Percentage')\n#     plt.xlabel(cols)\n#     plt.show()\n#     plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"014350feae83aa11713ee301ae295187996ec55f","scrolled":true},"cell_type":"code","source":"# #For numerical Data use Histogram excluding Outliers\n# for cols in (numerical_columns):\n#     series = X[cols]\n#     _100per = value_100per[cols].values[0]\n#     data = series[~series.isnull()]\n#     data = data[data <= _100per]\n#     count , bin_edges = np.histogram(data)\n#     print(count , bin_edges)\n#     print(_100per)\n#     (data).plot(kind='hist', xticks=bin_edges)\n#     plt.xlabel(cols)\n#     plt.show()\n#     plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffd6fc9805566ac7d076aa3a3ff390b0eef2f334"},"cell_type":"code","source":"# from scipy import stats\n# def give_relation(df , y_name , col_name):\n#     relation = pd.DataFrame(sec_X.corr().loc[col_name , [y_name]])\n#     relation.rename(columns={'SalePrice':'SalePrice_corr'} , inplace=True)\n#     corr_status = []\n#     for corr in relation['SalePrice_corr']:\n#         if corr > 0.8 or corr < -0.8:\n#             corr_status.append('strong')\n#         elif corr > 0.4 or corr < -0.4:\n#             corr_status.append('moderate')\n#         elif corr >0.1 or corr < -0.1:\n#             corr_status.append('weak')\n#         else:\n#             corr_status.append('very_weak or no corr')\n#     relation['Corr_status'] = corr_status\n#     p_values = []\n#     for col in col_name:\n#         pearson_coef , p_value = stats.pearsonr(sec_X[col] , y)\n#         p_values.append(p_value)\n#     relation['P_values'] = p_values\n#     status = []\n#     for p_value in p_values:\n#         if p_value < 0.001:\n#             status.append('Strong')\n#         elif p_value < 0.05:\n#             status.append('moderate')\n#         elif p_value <0.1:\n#             status.append('weak')\n#         elif p_value >= 0.1:\n#             status.append('no evidence')\n#     relation['P_value_Status'] = status\n#     return relation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09effb24b48749d2cf822cfd1ec2e078ddf96bb4","scrolled":true},"cell_type":"code","source":"# re = give_relation(sec_X , 'SalePrice' , numerical_columns + ordinal_columns)\n# re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb974f36a2070285e3aa08e296617d02602d6cd0","scrolled":true},"cell_type":"code","source":"# import seaborn as sb\n# for col in numerical_columns:\n#     df_col = pd.DataFrame(X[col])\n#     df_col.plot(kind='box')\n#     plt.show()\n#     plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"deadb9116d3a5e83c8108a6ace60c81cabdb4cd2"},"cell_type":"code","source":"# for col in numerical_columns:\n#     (sec_X).plot.scatter(x=col , y='SalePrice')\n#     plt.show()\n#     display(pd.DataFrame(re.loc[col]).transpose())\n#     plt.close()\n# for col in ordinal_columns:\n#     (sec_X).plot.scatter(x=col , y='SalePrice')\n#     plt.show()\n#     display(pd.DataFrame(re.loc[col]).transpose())\n#     plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d1e1d4c15e366b957d710e1a636afe6b0f991c5"},"cell_type":"code","source":"def get_missingcols(data , num_of_rows , message):\n    print(message)\n    total = data.isnull().sum().sort_values(ascending=False)\n    percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False) * 100\n    Type = data[total.index].dtypes\n    missing_data = pd.concat([total , percent , Type] , axis=1 , keys = ['Total' , 'Percent' , 'Type'])\n    print(missing_data.head(num_of_rows))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfae3dbab1df9d30ba5e785e902689c66e5fa834"},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n#Dealing With Numerical Columns\nimputed_training_data = X.copy()\nimputed_final_test_data=final_test_data.copy()\nnumeric_cols = numerical_columns\n#Imputation\nmy_imputer = SimpleImputer()\nimputed_training_data[numeric_cols] = my_imputer.fit_transform(imputed_training_data[numeric_cols])\nimputed_final_test_data[numeric_cols] = my_imputer.transform(imputed_final_test_data[numeric_cols])\n\n#Check Correctness of Imputation\nfor col in numeric_cols:\n    Check=None\n    if (imputed_training_data[col].isnull().any() or imputed_final_test_data[col].isnull().any()):\n        Check=False\n        break\n    if Check is False:\n        print(\"Imputation Not Done Corectly\")\nprint(imputed_training_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8711a416b9798db86478e4028f828b7febd0d8d","scrolled":true},"cell_type":"code","source":"columns_with_Na = [\"PoolQC\" , \"MiscFeature\" , \"Alley\" , \"Fence\" , \"FireplaceQu\" , \"GarageFinish\" , \"GarageType\" , \"GarageQual\" \n                    , \"GarageCond\" , \"BsmtExposure\" , \"BsmtFinType2\" , \"BsmtFinType1\" , \"BsmtCond\" , \"BsmtQual\",'GarageYrBlt'\n                  , \"Exterior2nd\" , \"Exterior1st\",\"BsmtFullBath\" , \"BsmtHalfBath\"]\ncolumns_with_no_Na = [\"MSZoning\" , \"Utilities\" , \"Functional\" , \"KitchenQual\" , \"SaleType\", \"Electrical\" , \"MasVnrType\"\n                     , 'GarageCars','MSSubClass' , 'OverallQual' , 'OverallCond' , 'YearBuilt' , 'YearRemodAdd' , 'FullBath' ,\n                      'HalfBath' , 'BedroomAbvGr','KitchenAbvGr','Fireplaces','MoSold','YrSold']\nfor col in columns_with_Na:\n    imputed_training_data[col].fillna(\"Na\" , inplace=True)\n    imputed_final_test_data[col].fillna(\"Na\" , inplace=True)\nfor col in columns_with_no_Na:\n    imputed_training_data[col].fillna(imputed_training_data[col].value_counts().idxmax(), inplace=True)\n    imputed_final_test_data[col].fillna(imputed_final_test_data[col].value_counts().idxmax() , inplace=True)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"647e5f4678bfa3c15b5f30332f4e0dee576ea3cb"},"cell_type":"code","source":"#Standardization\nfrom sklearn import preprocessing\nfor element in [ 'GarageCars','MSSubClass' , 'OverallQual' , 'OverallCond' , 'YearBuilt' , 'YearRemodAdd' , 'FullBath' ,\n                      'HalfBath' , 'BedroomAbvGr','KitchenAbvGr','Fireplaces','MoSold','YrSold']:\n    numerical_columns.remove(element)\nimputed_training_data[numerical_columns] = preprocessing.StandardScaler().fit_transform(imputed_training_data[numerical_columns])\nimputed_final_test_data[numerical_columns] = preprocessing.StandardScaler().fit_transform(imputed_final_test_data[numerical_columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"910cf68da7f668cfb2934db93b9b1491d6fec594"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport category_encoders as ce\ndef get_onehotencoding(data , columns):\n    encoded_data = pd.get_dummies(data[columns])\n    data.drop(columns , axis=1 , inplace=True)\n    return data.join(encoded_data)\n\ndef get_lowCardinalityCol(data, Columns):\n    return [col for col in Columns\n                        if data[col].nunique() <10]\n\ndef get_highCardinalityCol(Columns , low_CarCols):\n     return [col for col in Columns if col not in low_CarCols]\ndef apply_LabelEncoder_on(data , columns):\n    le = LabelEncoder()\n    for col in columns:\n        data[col] = le.fit_transform(data[col])\n    return data\ndef apply_BinaryEncoder_on(data , columns):\n    encoder = ce.BinaryEncoder()\n    encoded_data = encoder.fit_transform(data[columns])\n    data.drop(columns , axis=1 , inplace=True)\n    return data.join(encoded_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e552551a4ffabf516381a1a31d138c0f9ded8376"},"cell_type":"code","source":"# def compare_valuecount(X,y):\n#     columns_inX = X.select_dtypes(include=['object']).columns.tolist().sort()\n#     columns_iny = y.select_dtypes(include=['object']).columns.tolist().sort()\n#     len_ofValueCount_inX = []\n#     len_ofValueCount_iny = []\n#     for col in columns_inX:\n#         valuecount = X[col].value_counts()\n#         len_ofValueCount_inX.append(len(valuecount))\n#     for col in columns_iny:\n#         valuecount = y[col].value_counts()\n#         len_ofValueCount_iny.append(len(valuecount))\n#     print(len_ofValueCount)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"363c76c2cb96f2fc514d8bae322a8109b19c00d6","scrolled":true},"cell_type":"code","source":"#Dealing With Categorical Columns Using one hot encoding\ntraining_low_cardinality_cols = get_lowCardinalityCol(imputed_training_data, catagorical_columns)\ntest_low_cardinality_cols = get_lowCardinalityCol(imputed_final_test_data , catagorical_columns)\nHandled_training_data = get_onehotencoding(imputed_training_data , training_low_cardinality_cols)\nHandled_final_test_data = get_onehotencoding(imputed_final_test_data , test_low_cardinality_cols)\n\n#Using LabelEncoder\ntraining_high_cardinality_cols = get_highCardinalityCol(catagorical_columns,training_low_cardinality_cols)\ntest_high_cardinality_cols = get_highCardinalityCol(catagorical_columns,test_low_cardinality_cols)\n\nHandled_training_data = apply_LabelEncoder_on(Handled_training_data , training_high_cardinality_cols)\nHandled_final_test_data = apply_LabelEncoder_on(Handled_final_test_data , test_high_cardinality_cols)\n#Binary Encoding\nHandled_training_data = apply_BinaryEncoder_on(Handled_training_data , training_high_cardinality_cols)\nHandled_final_test_data = apply_BinaryEncoder_on(Handled_final_test_data , test_high_cardinality_cols)\n\nHandled_training_data, Handled_final_test_data = Handled_training_data.align(Handled_final_test_data,\n                                                                    join='left', \n                                                                    axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5402a93b9786d267d74e5bed46de8e024ab19c12"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import accuracy_score\n\ndef get_mae_using_RandomForest(X,y):\n    return -1 * cross_val_score(RandomForestRegressor(100 , random_state=1),\n                                X,y,\n                                scoring='neg_mean_absolute_error' , cv=5).mean()\n\ndef apply_XGBoot(X , y , final_test_data):\n    train_X , test_X , train_y , test_y = train_test_split(X , y , test_size=0.3)\n    mae = None\n    best_estimator = 0\n    best_rate=0.1\n    #This Loop Find the Best estimator\n    for n in range(1,1000 , 5):\n        print(n)\n        my_model = XGBRegressor(n_estimators=n ,n_jobs=4)\n        print(my_model)\n        my_model.fit(train_X , train_y)\n        prediction = my_model.predict(test_X)\n        print(mean_absolute_error(prediction , test_y))\n        if mae is None:\n            mae = mean_absolute_error(prediction , test_y)\n            best_estimator = 1\n        elif mae > mean_absolute_error(prediction , test_y):\n            mae = mean_absolute_error(prediction , test_y)\n            best_estimator = n\n    mae=None\n    #This Loop Find the Best learning_rate\n    for rate in np.round(np.linspace(0 , 0.5 , 19) , 2):\n        print(rate)\n        my_model = XGBRegressor(n_estimators=best_estimator ,n_jobs=4 , learning_rate=rate)\n        print(my_model)\n        my_model.fit(train_X , train_y)\n        prediction = my_model.predict(test_X)\n        print(mean_absolute_error(prediction , test_y))\n        if mae is None:\n            mae = mean_absolute_error(prediction , test_y)\n            best_rate = 0.1\n        elif mae > mean_absolute_error(prediction , test_y):\n            mae = mean_absolute_error(prediction , test_y)\n            best_rate = rate\n    print(\"Best Mea\" , mae)\n    print(\"Best_estimator\" ,best_estimator)\n    print(\"Best_rate\",best_rate)\n    my_model = XGBRegressor(n_estimators=best_estimator , n_jobs=4 , learning_rate=best_rate)\n    my_model.fit(X , y , verbose=False)\n    prediction = my_model.predict(final_test_data)  \n    Tuple = (prediction ,mae)\n    return Tuple","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c1f82a1756e0ce6715668b9cd049a53216264d6"},"cell_type":"code","source":"get_mae_using_RandomForest(Handled_training_data , y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdd959c8a4925a8a1035b34374d6a8dbd28dc146"},"cell_type":"code","source":"(prediction , mea) = apply_XGBoot(Handled_training_data , y , Handled_final_test_data)\nprint(mea)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c7e8d7f0165753e6e5a3b98ca2e90b21589828d"},"cell_type":"code","source":"my_submission = pd.DataFrame({'Id': ID, 'SalePrice': prediction})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}